{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1GUI-pVs8ZI"
      },
      "source": [
        "# Step 0: Global Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moOK6eq3zzDk",
        "outputId": "895e19a6-b2f7-4e49-ed7c-2267b3cae0a0"
      },
      "outputs": [],
      "source": [
        "# !pip install exchange_calendars\n",
        "# !pip install gymnasium\n",
        "# !pip install yfinance stockstats\n",
        "# !pip install optuna\n",
        "# !pip install stable_baselines3\n",
        "# !pip install pyportfolioopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "PhdTyGyzvM4M"
      },
      "outputs": [],
      "source": [
        "#global variables\n",
        "Tickers = [\"AAPL\", \"COST\", \"CVX\", \"MSFT\", \"JNJ\", \"NVDA\", \"PG\", \"UNH\", \"V\", \"WMT\"]\n",
        "#randomly chosen from top 30 tickers.\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2024-03-13'\n",
        "time_interval = \"1H\"\n",
        "# INDICATORS = [\n",
        "#     \"macd\",\n",
        "#     \"boll_ub\",\n",
        "#     \"boll_lb\",\n",
        "#     \"rsi_30\",\n",
        "#     \"cci_30\",\n",
        "#     \"dx_30\",\n",
        "#     \"close_30_sma\",\n",
        "#     \"close_60_sma\",\n",
        "# ]\n",
        "#only indicator we used is s&p 500 rn\n",
        "INDICATORS = ['sp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "Jf2eOetqtTp8"
      },
      "outputs": [],
      "source": [
        "#global libraries\n",
        "import datetime\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "from sqlite3 import Timestamp\n",
        "from typing import Any\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Optional\n",
        "from typing import Type\n",
        "from typing import TypeVar\n",
        "from typing import Union\n",
        "\n",
        "import exchange_calendars as tc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import yfinance as yf\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import gymnasium as gym\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from gymnasium import spaces\n",
        "from gymnasium.utils import seeding\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from stable_baselines3.common.logger import Logger, KVWriter, CSVOutputFormat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqss27cEIaE5"
      },
      "source": [
        "# Step 1: Data Preprocessing\n",
        "We used hourly US historical stock data from Kaggle dataset, from 2022/1/1 to 2024/3/15. Since the author of dataset is located in Moscow, when cleaning the data, we converted the timezone to New York, then added S&P indexes as a benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "36_4Es4us2ob"
      },
      "outputs": [],
      "source": [
        "def import_data(tickers: list[str]) -> dict[str, pd.DataFrame]:\n",
        "  dataframes = {}\n",
        "  for ticker in tickers:\n",
        "    filename = f\"{ticker}.US_H1.csv\"\n",
        "    df = pd.read_csv(filename)\n",
        "    dataframes[ticker] = df\n",
        "  return dataframes\n",
        "\n",
        "def process_datetime(row):\n",
        "    dt = pd.to_datetime(row['datetime'])\n",
        "    dt_moscow = pytz.timezone('Europe/Moscow').localize(dt)\n",
        "    dt_new_york = dt_moscow.astimezone(pytz.timezone('America/New_York'))\n",
        "    return dt_new_york\n",
        "\n",
        "\n",
        "def clean_data(tickers: list[str], start_date: date, end_date: date) -> pd.DataFrame:\n",
        "  # tic_list = tickers\n",
        "  dataframes = import_data(tickers)\n",
        "\n",
        "  # trading_days = get_trading_days(start=start_date, end=end_date)\n",
        "  new_df = pd.DataFrame()\n",
        "  for ticker, df in dataframes.items():\n",
        "      # Add \"tic\" column\n",
        "      df[\"tic\"] = ticker\n",
        "      df = df.sort_values(by='datetime', ascending=True)\n",
        "      # Rename \"datetime\" to \"timestamp\"\n",
        "      # df.rename(columns={\"datetime\": \"timestamp\"}, inplace=True)\n",
        "      date_formats = [\"%Y-%m-%d %H:%M\", \"%m/%d/%Y %I:%M:%S %p\"]\n",
        "\n",
        "  # Iterate over each format and try to convert datetime\n",
        "      for date_format in date_formats:\n",
        "          try:\n",
        "              df['datetime'] = pd.to_datetime(df['datetime'], format=date_format)\n",
        "              break\n",
        "          except ValueError:\n",
        "              pass\n",
        "      df['datetime'] = df.apply(lambda row: process_datetime(row), axis=1)\n",
        "\n",
        "\n",
        "      all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
        "      complete_df = pd.DataFrame(all_days, columns=['datetime'])\n",
        "      complete_df['key'] = 1\n",
        "      df['key'] = 1\n",
        "\n",
        "      # Merge to align existing data with the complete timeframe\n",
        "      merged_df = pd.merge(complete_df, df, on='datetime', how='left')\n",
        "      # merged_df.drop(['key'], axis=1, inplace=True)\n",
        "\n",
        "      # Forward fill missing data\n",
        "      merged_df['tic'].fillna(method='ffill', inplace=True)\n",
        "      merged_df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "      # Filter rows to include only 9 AM to 4 PM and weekdays\n",
        "      merged_df = merged_df[merged_df['datetime'].dt.hour.between(9, 16)]\n",
        "      merged_df = merged_df[merged_df['datetime'].dt.weekday < 5]\n",
        "\n",
        "      # Concatenate the prepared data for this ticker to the new DataFrame\n",
        "      new_df = pd.concat([new_df, merged_df], ignore_index=True)\n",
        "\n",
        "  new_df = new_df.reset_index()\n",
        "  new_df = new_df.rename(columns={\"index\": \"timestamp\"})\n",
        "  return new_df\n",
        "\n",
        "def add_sp(data):\n",
        "  sp = pd.read_csv('S&P500.csv')\n",
        "  #convert to same format\n",
        "  data['date'] = pd.to_datetime(data['datetime']).dt.normalize()\n",
        "  sp['Date'] = pd.to_datetime(sp['Date']).dt.tz_localize('America/New_York')\n",
        "\n",
        "  combined_df = pd.merge(data, sp, left_on='date', right_on='Date', how='left')\n",
        "  combined_df.fillna(method='ffill', inplace=True)\n",
        "  #merge by same date\n",
        "  combined_df['sp'] = combined_df['Close/Last']\n",
        "  combined_df = combined_df.drop(columns=['Date', 'Close/Last', 'Open', 'High', 'Low', 'date'])\n",
        "  combined_df['date'] = combined_df['datetime']\n",
        "  return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5OO1_gOFH89S",
        "outputId": "a4ef30e7-e9dd-404f-e95d-72c7ed98792f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  all_days = pd.date_range(start=start_date, end=end_date, freq='H', tz='America/New_York')\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:50: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['tic'].fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df.fillna(method='ffill', inplace=True)\n",
            "C:\\Users\\muchi\\AppData\\Local\\Temp\\ipykernel_23536\\2214824550.py:71: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  combined_df.fillna(method='ffill', inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>datetime</th>\n",
              "      <th>key_x</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>key_y</th>\n",
              "      <th>sp</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2022-01-03 09:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>177.83</td>\n",
              "      <td>180.93</td>\n",
              "      <td>177.71</td>\n",
              "      <td>180.45</td>\n",
              "      <td>12571329.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 09:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2022-01-03 10:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>180.46</td>\n",
              "      <td>181.43</td>\n",
              "      <td>180.27</td>\n",
              "      <td>180.96</td>\n",
              "      <td>12817320.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 10:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-01-03 11:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>180.95</td>\n",
              "      <td>181.77</td>\n",
              "      <td>180.39</td>\n",
              "      <td>181.47</td>\n",
              "      <td>9409836.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 11:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2022-01-03 12:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>181.47</td>\n",
              "      <td>182.17</td>\n",
              "      <td>181.08</td>\n",
              "      <td>181.69</td>\n",
              "      <td>7256820.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 12:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2022-01-03 13:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>181.69</td>\n",
              "      <td>182.88</td>\n",
              "      <td>181.64</td>\n",
              "      <td>182.37</td>\n",
              "      <td>9391830.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 13:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2022-01-03 14:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>182.37</td>\n",
              "      <td>182.47</td>\n",
              "      <td>181.66</td>\n",
              "      <td>181.88</td>\n",
              "      <td>7665642.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 14:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2022-01-03 15:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>181.87</td>\n",
              "      <td>182.20</td>\n",
              "      <td>181.20</td>\n",
              "      <td>182.00</td>\n",
              "      <td>12634063.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 15:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2022-01-03 16:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>182.01</td>\n",
              "      <td>182.01</td>\n",
              "      <td>182.00</td>\n",
              "      <td>182.01</td>\n",
              "      <td>7016928.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4796.56</td>\n",
              "      <td>2022-01-03 16:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2022-01-04 09:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>182.63</td>\n",
              "      <td>182.94</td>\n",
              "      <td>181.49</td>\n",
              "      <td>182.26</td>\n",
              "      <td>11553605.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4793.54</td>\n",
              "      <td>2022-01-04 09:00:00-05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2022-01-04 10:00:00-05:00</td>\n",
              "      <td>1</td>\n",
              "      <td>182.27</td>\n",
              "      <td>182.68</td>\n",
              "      <td>180.97</td>\n",
              "      <td>181.03</td>\n",
              "      <td>14797301.0</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4793.54</td>\n",
              "      <td>2022-01-04 10:00:00-05:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   timestamp                  datetime  key_x    open    high     low   close  \\\n",
              "0          0 2022-01-03 09:00:00-05:00      1  177.83  180.93  177.71  180.45   \n",
              "1          1 2022-01-03 10:00:00-05:00      1  180.46  181.43  180.27  180.96   \n",
              "2          2 2022-01-03 11:00:00-05:00      1  180.95  181.77  180.39  181.47   \n",
              "3          3 2022-01-03 12:00:00-05:00      1  181.47  182.17  181.08  181.69   \n",
              "4          4 2022-01-03 13:00:00-05:00      1  181.69  182.88  181.64  182.37   \n",
              "5          5 2022-01-03 14:00:00-05:00      1  182.37  182.47  181.66  181.88   \n",
              "6          6 2022-01-03 15:00:00-05:00      1  181.87  182.20  181.20  182.00   \n",
              "7          7 2022-01-03 16:00:00-05:00      1  182.01  182.01  182.00  182.01   \n",
              "8          8 2022-01-04 09:00:00-05:00      1  182.63  182.94  181.49  182.26   \n",
              "9          9 2022-01-04 10:00:00-05:00      1  182.27  182.68  180.97  181.03   \n",
              "\n",
              "       volume   tic  key_y       sp                      date  \n",
              "0  12571329.0  AAPL    1.0  4796.56 2022-01-03 09:00:00-05:00  \n",
              "1  12817320.0  AAPL    1.0  4796.56 2022-01-03 10:00:00-05:00  \n",
              "2   9409836.0  AAPL    1.0  4796.56 2022-01-03 11:00:00-05:00  \n",
              "3   7256820.0  AAPL    1.0  4796.56 2022-01-03 12:00:00-05:00  \n",
              "4   9391830.0  AAPL    1.0  4796.56 2022-01-03 13:00:00-05:00  \n",
              "5   7665642.0  AAPL    1.0  4796.56 2022-01-03 14:00:00-05:00  \n",
              "6  12634063.0  AAPL    1.0  4796.56 2022-01-03 15:00:00-05:00  \n",
              "7   7016928.0  AAPL    1.0  4796.56 2022-01-03 16:00:00-05:00  \n",
              "8  11553605.0  AAPL    1.0  4793.54 2022-01-04 09:00:00-05:00  \n",
              "9  14797301.0  AAPL    1.0  4793.54 2022-01-04 10:00:00-05:00  "
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = clean_data(Tickers, start_date, end_date)\n",
        "new_df = add_sp(new_df)\n",
        "new_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZirt-a1T4QE"
      },
      "source": [
        "# Step 2: Data Splittng\n",
        "Split the data into two parts - 19 months for training the agents, and 9 for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "M8sqleV-FhZ4"
      },
      "outputs": [],
      "source": [
        "def data_split(df, start, end, target_date_col=\"datetime\"):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
        "\n",
        "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
        "    data.index = data[target_date_col].factorize()[0]\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "J9V_Fc4DUAVR"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2022-01-01'\n",
        "TRAIN_END_DATE = '2023-07-01'\n",
        "TEST_START_DATE = '2023-07-01'\n",
        "TEST_END_DATE = '2024-03-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmiGuSibUX_j",
        "outputId": "a178aebd-48dd-4d9b-987a-df8c7e2e3ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31200\n",
            "13920\n"
          ]
        }
      ],
      "source": [
        "train = data_split(new_df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "test = data_split(new_df, TEST_START_DATE, TEST_END_DATE)\n",
        "train_length = len(train)\n",
        "test_length = len(test)\n",
        "print(train_length)\n",
        "print(test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M3JWZaMzUoJt",
        "outputId": "86645ebb-3189-4b53-944f-3d99a2ef6814"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>datetime</th>\n",
              "      <th>key_x</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>key_y</th>\n",
              "      <th>sp</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>25999</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "      <td>1</td>\n",
              "      <td>423.13</td>\n",
              "      <td>423.16</td>\n",
              "      <td>422.78</td>\n",
              "      <td>422.81</td>\n",
              "      <td>15705.0</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4450.38</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>30575</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "      <td>1</td>\n",
              "      <td>151.78</td>\n",
              "      <td>151.80</td>\n",
              "      <td>151.67</td>\n",
              "      <td>151.74</td>\n",
              "      <td>3664992.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4450.38</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>35151</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "      <td>1</td>\n",
              "      <td>480.96</td>\n",
              "      <td>481.04</td>\n",
              "      <td>480.47</td>\n",
              "      <td>480.64</td>\n",
              "      <td>895538.0</td>\n",
              "      <td>UNH</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4450.38</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>39727</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "      <td>1</td>\n",
              "      <td>237.49</td>\n",
              "      <td>237.53</td>\n",
              "      <td>237.32</td>\n",
              "      <td>237.48</td>\n",
              "      <td>1415378.0</td>\n",
              "      <td>V</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4450.38</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>44303</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "      <td>1</td>\n",
              "      <td>157.27</td>\n",
              "      <td>157.28</td>\n",
              "      <td>157.16</td>\n",
              "      <td>157.18</td>\n",
              "      <td>1349958.0</td>\n",
              "      <td>WMT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4450.38</td>\n",
              "      <td>2023-06-30 16:00:00-04:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      timestamp                  datetime  key_x    open    high     low  \\\n",
              "3119      25999 2023-06-30 16:00:00-04:00      1  423.13  423.16  422.78   \n",
              "3119      30575 2023-06-30 16:00:00-04:00      1  151.78  151.80  151.67   \n",
              "3119      35151 2023-06-30 16:00:00-04:00      1  480.96  481.04  480.47   \n",
              "3119      39727 2023-06-30 16:00:00-04:00      1  237.49  237.53  237.32   \n",
              "3119      44303 2023-06-30 16:00:00-04:00      1  157.27  157.28  157.16   \n",
              "\n",
              "       close     volume   tic  key_y       sp                      date  \n",
              "3119  422.81    15705.0  NVDA    1.0  4450.38 2023-06-30 16:00:00-04:00  \n",
              "3119  151.74  3664992.0    PG    1.0  4450.38 2023-06-30 16:00:00-04:00  \n",
              "3119  480.64   895538.0   UNH    1.0  4450.38 2023-06-30 16:00:00-04:00  \n",
              "3119  237.48  1415378.0     V    1.0  4450.38 2023-06-30 16:00:00-04:00  \n",
              "3119  157.18  1349958.0   WMT    1.0  4450.38 2023-06-30 16:00:00-04:00  "
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DCPRJbEuXGF"
      },
      "source": [
        "# Step 3: Construct Environment\n",
        "Build training environment mimicing openAI gym, so that it works with stable baseline3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_hvEQvvmwUH",
        "outputId": "a0b6bc63-cba5-4354-baae-9ab36d196d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 10, State Space: 31\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "INDICATORS = ['sp']\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "#class make it easier to store variables\n",
        "class TradingEnvironment(gym.Env):\n",
        "    metadata = {\"render.modes\": [\"human\"]}\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        stock_dim: int,\n",
        "        hmax: int,\n",
        "        initial_amount: int,\n",
        "        num_stock_shares: list[int],\n",
        "        buy_cost_pct: list[float],\n",
        "        sell_cost_pct: list[float],\n",
        "        reward_scaling: float,\n",
        "        state_space: int,\n",
        "        action_space: int,\n",
        "        tech_indicator_list: list[str],\n",
        "        print_verbosity=10,\n",
        "        totalhour = 0,\n",
        "        day=0,\n",
        "        hour=9,\n",
        "        initial=True,\n",
        "        previous_state=[],\n",
        "        iteration=\"\",\n",
        "    ):\n",
        "        self.day = day\n",
        "        self.hour = hour\n",
        "        self.totalhour = totalhour\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.num_stock_shares = num_stock_shares\n",
        "        self.initial_amount = initial_amount  # get the initial cash\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
        "        )\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.terminal = False\n",
        "        self.print_verbosity = print_verbosity\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        self.iteration = iteration\n",
        "        # initalize state\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.tests = 0\n",
        "        self.episode = 0\n",
        "        #store all the total balance change\n",
        "        self.balance_memory = [\n",
        "            self.initial_amount\n",
        "            + np.sum(\n",
        "                np.array(self.num_stock_shares)\n",
        "                * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "            )\n",
        "        ]\n",
        "        #cash + current stock (should be 0)\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.state_memory = ([])\n",
        "        #store the state in middle of training\n",
        "        self.date_memory = [self._get_date()]\n",
        "        self._seed()\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        if (self.state[index + 2 * self.stock_dim + 1] != True):  #if price > 0 (correct data:)\n",
        "            if self.state[index + self.stock_dim + 1] > 0:\n",
        "                #if holding more than 0 shares\n",
        "                sell_num_shares = min(abs(action), self.state[index + self.stock_dim + 1])\n",
        "                sell_amount = (\n",
        "                    self.state[index + 1]\n",
        "                    * sell_num_shares\n",
        "                    * (1 - self.sell_cost_pct[index]))\n",
        "                # update balance and do sell\n",
        "                self.state[0] += sell_amount\n",
        "\n",
        "                self.state[index + self.stock_dim + 1] -= sell_num_shares\n",
        "                self.cost += (\n",
        "                    self.state[index + 1]\n",
        "                    * sell_num_shares\n",
        "                    * self.sell_cost_pct[index])\n",
        "                self.tests += 1\n",
        "            else:\n",
        "                sell_num_shares = 0\n",
        "        else:\n",
        "            sell_num_shares = 0\n",
        "\n",
        "        return sell_num_shares\n",
        "\n",
        "\n",
        "    def _buy_stock(self, index, action):\n",
        "        if (self.state[index + 2 * self.stock_dim + 1] != True):\n",
        "            available_amount = self.state[0] // (self.state[index + 1] * (1 + self.buy_cost_pct[index])) \n",
        "            #check cost of trading and get max available\n",
        "\n",
        "            #get as much as possible\n",
        "            buy_num_shares = min(available_amount, action)\n",
        "            #   print(available_amount)\n",
        "            buy_amount = (\n",
        "                self.state[index + 1]\n",
        "                * buy_num_shares\n",
        "                * (1 + self.buy_cost_pct[index])\n",
        "            )\n",
        "            self.state[0] -= buy_amount\n",
        "\n",
        "            self.state[index + self.stock_dim + 1] += buy_num_shares\n",
        "            self.cost += (\n",
        "                self.state[index + 1] * buy_num_shares * self.buy_cost_pct[index]\n",
        "            )\n",
        "            self.tests += 1\n",
        "        else:\n",
        "            buy_num_shares = 0\n",
        "\n",
        "        return buy_num_shares\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        # Adjust the terminal condition to account for daily trading hours\n",
        "        self.terminal = self.totalhour >= len(self.df.index.unique()) - 1 // 8 - 1\n",
        "\n",
        "        if self.terminal:\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "            df_total_value = pd.DataFrame(self.balance_memory)\n",
        "            tot_reward = (\n",
        "                self.state[0]\n",
        "                + sum(\n",
        "                    np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                    * np.array(\n",
        "                        self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
        "                    )\n",
        "                )\n",
        "                - self.balance_memory[0]\n",
        "            )\n",
        "            # initial_amount is only cash part of our initial asset\n",
        "            df_total_value.columns = [\"account_value\"]\n",
        "            df_total_value[\"date\"] = self.date_memory\n",
        "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "            if df_total_value[\"daily_return\"].std() != 0:\n",
        "                sharpe = (\n",
        "                    (252**0.5)\n",
        "                    * df_total_value[\"daily_return\"].mean()\n",
        "                    / df_total_value[\"daily_return\"].std()\n",
        "                )\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.columns = [\"account_rewards\"]\n",
        "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
        "            if self.episode % self.print_verbosity == 0:\n",
        "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
        "                print(f\"begin_total_asset: {self.balance_memory[0]:0.2f}\")\n",
        "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
        "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
        "                print(f\"total_cost: {self.cost:0.2f}\")\n",
        "                print(f\"total_tests: {self.tests}\")\n",
        "                if df_total_value[\"daily_return\"].std() != 0:\n",
        "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
        "                print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal, False, {}\n",
        "\n",
        "        else:\n",
        "            actions = actions * self.hmax #scale actions\n",
        "            actions = actions.astype(int)\n",
        "            begin_total_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            sell_index = argsort_actions[:np.count_nonzero(actions < 0)]\n",
        "            buy_index = argsort_actions[::-1][:np.count_nonzero(actions > 0)]\n",
        "            for index in sell_index:\n",
        "                actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
        "\n",
        "            for index in buy_index:\n",
        "                actions[index] = self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.actions_memory.append(actions)\n",
        "\n",
        "            # Transition to the next state\n",
        "            self.totalhour += 1\n",
        "            self.hour += 1\n",
        "            if self.hour > 16:  #Count for time and day\n",
        "                self.hour = 9\n",
        "                self.day += 1  # Move to the next day\n",
        "\n",
        "            # Ensure that data fetching considers both day and hour\n",
        "            self.data = self.df.loc[self.totalhour, :]\n",
        "            self.state = self._update_state()\n",
        "\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            )\n",
        "\n",
        "            self.state = self._update_state()\n",
        "            self.balance_memory.append(end_total_asset)\n",
        "            self.date_memory.append(self._get_date())\n",
        "            self.reward = end_total_asset - begin_total_asset\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            self.state_memory.append(self.state)\n",
        "\n",
        "            return self.state, self.reward, self.terminal, False, {}\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed=None,\n",
        "        options=None,\n",
        "    ):\n",
        "        # initiate state\n",
        "        self.day = 0\n",
        "        self.totalhour = 0\n",
        "        self.hour = 9\n",
        "        self.data = self.df.loc[self.totalhour, :]\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        if self.initial:\n",
        "            self.balance_memory = [\n",
        "                self.initial_amount\n",
        "                + np.sum(\n",
        "                    np.array(self.num_stock_shares)\n",
        "                    * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "                )\n",
        "            ]\n",
        "        else:\n",
        "            previous_total_asset = self.previous_state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(\n",
        "                    self.previous_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
        "                )\n",
        "            )\n",
        "            self.balance_memory = [previous_total_asset]\n",
        "\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.tests = 0\n",
        "        self.terminal = False\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.date_memory = [self._get_date()]\n",
        "\n",
        "        self.episode += 1\n",
        "        return self.state, {}\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        return self.state\n",
        "\n",
        "    def _initiate_state(self):\n",
        "        if self.initial:\n",
        "            # For Initial State\n",
        "            state = (\n",
        "                [self.initial_amount]\n",
        "                + self.data.close.values.tolist()\n",
        "                + self.num_stock_shares\n",
        "                + sum((self.data[tech].values.tolist() for tech in self.tech_indicator_list),\n",
        "                    [],\n",
        "                )\n",
        "            ) \n",
        "            \n",
        "        else:\n",
        "            # Using Previous State\n",
        "            state = (\n",
        "                [self.previous_state[0]]\n",
        "                + self.data.close.values.tolist()\n",
        "                + self.previous_state[\n",
        "                    (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
        "                ]\n",
        "                + sum(\n",
        "                    (self.data[tech].values.tolist() for tech in self.tech_indicator_list),\n",
        "                    [],\n",
        "                )\n",
        "            )\n",
        "            \n",
        "        return state\n",
        "\n",
        "    def _update_state(self):\n",
        "        state = (\n",
        "            [self.state[0]]\n",
        "            + self.data.close.values.tolist()\n",
        "            + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            + sum(\n",
        "                (self.data[tech].values.tolist() for tech in self.tech_indicator_list),\n",
        "                [],\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_date(self):\n",
        "        date = self.data.date.unique()[0]\n",
        "\n",
        "    def save_balance_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        asset_list = self.balance_memory\n",
        "        df_account_value = pd.DataFrame(\n",
        "            {\"date\": date_list, \"account_value\": asset_list}\n",
        "        )\n",
        "        return df_account_value\n",
        "    \n",
        "    # add save_state_memory to preserve state in the trading process\n",
        "    def save_state_memory(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            # date and close price length must match actions length\n",
        "            date_list = self.date_memory[:-1]\n",
        "            df_date = pd.DataFrame(date_list)\n",
        "            df_date.columns = [\"date\"]\n",
        "\n",
        "            state_list = self.state_memory\n",
        "            df_states = pd.DataFrame(\n",
        "                state_list,\n",
        "                columns=[\"cash\"],\n",
        "            )\n",
        "            df_states.index = df_date.date\n",
        "        return df_states\n",
        "\n",
        "    def save_balance_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        asset_list = self.balance_memory\n",
        "        df_account_value = pd.DataFrame({\"date\": date_list, \"account_value\": asset_list})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory[:-1]\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = [\"date\"]\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sq6Xp13Hbky"
      },
      "source": [
        "# Step 4: Stable Baselines3 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "sXmB6jWOIUat"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "DATA_SAVE_DIR = \"datasets\"\n",
        "TRAINED_MODEL_DIR = \"trained_models\"\n",
        "TENSORBOARD_LOG_DIR = \"tensorboard_log\"\n",
        "RESULTS_DIR = \"results\"\n",
        "\n",
        "# Model Parameters\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.0007}\n",
        "PPO_PARAMS = {\"n_steps\": 2048, \"ent_coef\": 0.01, \"learning_rate\": 0.00025, \"batch_size\": 64}\n",
        "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DRL\n",
        "\n",
        "# DRL models from Stable Baselines 3\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "\n",
        "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"ppo\": PPO}\n",
        "MODEL_KWARGS = {\n",
        "    \"a2c\": A2C_PARAMS,\n",
        "    \"ppo\": PPO_PARAMS,\n",
        "    \"ddpg\": DDPG_PARAMS,\n",
        "    \"td3\": TD3_PARAMS,\n",
        "}\n",
        "\n",
        "NOISE = {\n",
        "    \"normal\": NormalActionNoise,\n",
        "    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
        "}\n",
        "\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    \n",
        "    #Custom callback for plotting additional values in tensorboard.\n",
        "    \n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        try:\n",
        "            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n",
        "\n",
        "        except BaseException as error:\n",
        "            try:\n",
        "                self.logger.record(key=\"train/reward\", value=self.locals[\"reward\"][0])\n",
        "\n",
        "            except BaseException as inner_error:\n",
        "                # Handle the case where neither \"rewards\" nor \"reward\" is found\n",
        "                self.logger.record(key=\"train/reward\", value=None)\n",
        "                # Print the original error and the inner error for debugging\n",
        "                print(\"Original Error:\", error)\n",
        "                print(\"Inner Error:\", inner_error)\n",
        "        return True\n",
        "\n",
        "\n",
        "class DRLAgent:\n",
        "    #help call agents with given gym environment\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def get_model(\n",
        "        self,\n",
        "        model_name,\n",
        "        policy=\"MlpPolicy\",\n",
        "        policy_kwargs=None,\n",
        "        model_kwargs=None,\n",
        "        verbose=1,\n",
        "        seed=None,\n",
        "        tensorboard_log=None,\n",
        "    ):\n",
        "        if model_name not in MODELS:\n",
        "            raise ValueError(\n",
        "                f\"Model '{model_name}' not found in MODELS.\"\n",
        "            )  # this is more informative than NotImplementedError(\"NotImplementedError\")\n",
        "\n",
        "        if model_kwargs is None:\n",
        "            model_kwargs = MODEL_KWARGS[model_name]\n",
        "\n",
        "        if \"action_noise\" in model_kwargs:\n",
        "            n_actions = self.env.action_space.shape[-1]\n",
        "            model_kwargs[\"action_noise\"] = NOISE[model_kwargs[\"action_noise\"]](\n",
        "                mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions)\n",
        "            )\n",
        "        print(model_kwargs)\n",
        "        return MODELS[model_name](\n",
        "            policy=policy,\n",
        "            env=self.env,\n",
        "            tensorboard_log=tensorboard_log,\n",
        "            verbose=verbose,\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            seed=seed,\n",
        "            **model_kwargs,\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def train_model(model, tb_log_name, total_timesteps=5000):  \n",
        "        model = model.learn(\n",
        "            total_timesteps=total_timesteps,\n",
        "            tb_log_name=tb_log_name,\n",
        "            callback=TensorboardCallback(),\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def DRL_prediction(model, environment, deterministic=True):\n",
        "        #make prediction\n",
        "        test_env, test_obs = environment.get_sb_env()\n",
        "        account_memory = None  #avoid unnecessary list creation\n",
        "        actions_memory = None\n",
        "\n",
        "        test_env.reset()\n",
        "        max_steps = len(environment.df.index.unique()) - 1\n",
        "\n",
        "        for i in range(len(environment.df.index.unique())):\n",
        "            action, _states = model.predict(test_obs, deterministic=deterministic)\n",
        "            test_obs, rewards, dones, info = test_env.step(action)\n",
        "\n",
        "            if (i == max_steps - 1):\n",
        "                account_memory = test_env.env_method(method_name=\"save_balance_memory\")\n",
        "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
        "            # add current state to state memory\n",
        "            if dones[0]:\n",
        "                print(\"Prediction Complete\")\n",
        "                break\n",
        "        return account_memory[0], actions_memory[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKqimXDsu-12"
      },
      "source": [
        "# Step 5: Train Agents\n",
        "Train three agents baised on different algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Environment Construction\n",
        "e_train_gym = TradingEnvironment(df = train, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "sCm2qFRBvCZT"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "#select algorithm in use\n",
        "if_using_a2c = True\n",
        "if_using_ddpg = True\n",
        "if_using_ppo = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "xxjhm6S0LK6x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from stable_baselines3.common.logger import Logger, configure\n",
        "\n",
        "def configure_logger(log_dir, formats):\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    logger = Logger(\n",
        "        folder=log_dir,\n",
        "        output_formats=[format_ for format_ in formats if format_ in [\"stdout\", \"csv\", \"tensorboard\"]]\n",
        "    )\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wygIjjIIK5TV",
        "outputId": "666ea2f4-346d-41b4-fb32-93eaa6da8376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "if if_using_a2c:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/a2c'\n",
        "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_a2c.set_logger(new_logger_a2c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "XM2SaVB2LQ43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 413      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.3    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 2.07e+04 |\n",
            "|    reward             | 2030.15  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 6.78e+06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 438       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -1.45e+04 |\n",
            "|    reward             | -36.46    |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.98e+06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 449      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.3    |\n",
            "|    explained_variance | 0.00077  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 2.08e+04 |\n",
            "|    reward             | 325.0086 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 9.48e+06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 447       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -1.52e+05 |\n",
            "|    reward             | 329.5853  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.22e+08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 453       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 7.31e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 3.38e+04  |\n",
            "|    reward             | 5371.4023 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 7.81e+06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 443      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.2    |\n",
            "|    explained_variance | 0.000598 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -57.6    |\n",
            "|    reward             | 430.1427 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 2.9e+06  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 435        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | -0.000106  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -1.27e+05  |\n",
            "|    reward             | -1486.9861 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.08e+08   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 430       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 4.38e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -1.14e+04 |\n",
            "|    reward             | 7031.757  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.64e+07  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 427        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.000349   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -2.92e+04  |\n",
            "|    reward             | -1698.1611 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 6.4e+06    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 424       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 1.01e+04  |\n",
            "|    reward             | 788.84827 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.47e+05  |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=5000) if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFgoLoL5mPHN",
        "outputId": "eceb559d-f71a-4e80-dd9d-fc11f39f8b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/ddpg\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "if if_using_ddpg:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ddpg'\n",
        "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ddpg.set_logger(new_logger_ddpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "dy9WZcQmmRBG"
      },
      "outputs": [],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=5000) if if_using_ddpg else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GykVFct-mXyd",
        "outputId": "2e69013b-d4ba-4ae4-84eb-9785f06b135f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to results/ppo\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "\n",
        "if if_using_ppo:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ppo'\n",
        "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ppo.set_logger(new_logger_ppo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-SZP4KbmbRb",
        "outputId": "6a861787-0807-4d48-98b8-1ac7d241171a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 656        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 3          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -3014.6902 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 214         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005292926 |\n",
            "|    clip_fraction        | 0.0261      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -14.2       |\n",
            "|    explained_variance   | -8.34e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.64e+07    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00606    |\n",
            "|    reward               | -3954.537   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.34e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 156          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062101143 |\n",
            "|    clip_fraction        | 0.0402       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -14.2        |\n",
            "|    explained_variance   | 2.74e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.05e+07     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00707     |\n",
            "|    reward               | 1534.9996    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.1e+08      |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=5000) if if_using_ppo else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-WBxGRhm97m"
      },
      "source": [
        "# Step 6: Backtesting\n",
        "Compare and evaluate performance of three models as well as prediction from Mean-Variance Optimization (MVO) methdology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl7s6HYznCXe",
        "outputId": "4d961cd3-080b-4ef7-bf81-15860d535348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 10, State Space: 31\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(test.tic.unique())\n",
        "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "e_test_gym = TradingEnvironment(df = test, **env_kwargs)\n",
        "#new test environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Complete\n"
          ]
        }
      ],
      "source": [
        "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
        "    model=trained_a2c, \n",
        "    environment = e_test_gym) if if_using_a2c else (None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Complete\n"
          ]
        }
      ],
      "source": [
        "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_test_gym) if if_using_ddpg else (None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Complete\n"
          ]
        }
      ],
      "source": [
        "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
        "    model=trained_ppo, \n",
        "    environment = e_test_gym) if if_using_ppo else (None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_df_for_mvo(df):\n",
        "  return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
        "\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
        "  return (np.diff(StockPrice, axis=0) / StockPrice[:-1]) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[192.94, 538.21, 157.16, ..., 479.08, 236.66, 157.48],\n",
              "       [191.98, 539.56, 157.62, ..., 478.41, 236.61, 158.03],\n",
              "       [192.23, 539.88, 157.79, ..., 478.42, 237.65, 158.38],\n",
              "       ...,\n",
              "       [180.2 , 749.19, 152.22, ..., 493.31, 283.01,  58.79],\n",
              "       [180.74, 743.59, 152.12, ..., 493.53, 282.66,  58.62],\n",
              "       [180.72, 743.27, 152.01, ..., 493.6 , 282.64,  58.61]])"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "StockData = process_df_for_mvo(train)\n",
        "testData = process_df_for_mvo(test)\n",
        "\n",
        "testData.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean returns of assets in k-portfolio 1\n",
            " [ 0.004  0.001  0.012 -0.     0.003  0.019 -0.001  0.001  0.005  0.004]\n",
            "Variance-Covariance matrix of returns\n",
            " [[0.442 0.228 0.135 0.076 0.345 0.54  0.103 0.138 0.258 0.123]\n",
            " [0.228 0.365 0.092 0.087 0.225 0.322 0.123 0.138 0.173 0.182]\n",
            " [0.135 0.092 0.504 0.047 0.108 0.196 0.029 0.097 0.105 0.062]\n",
            " [0.076 0.087 0.047 0.151 0.073 0.047 0.094 0.108 0.073 0.07 ]\n",
            " [0.345 0.225 0.108 0.073 0.508 0.607 0.109 0.133 0.258 0.117]\n",
            " [0.54  0.322 0.196 0.047 0.607 1.655 0.098 0.179 0.41  0.12 ]\n",
            " [0.103 0.123 0.029 0.094 0.109 0.098 0.198 0.108 0.096 0.101]\n",
            " [0.138 0.138 0.097 0.108 0.133 0.179 0.108 0.31  0.118 0.091]\n",
            " [0.258 0.173 0.105 0.073 0.258 0.41  0.096 0.118 0.407 0.096]\n",
            " [0.123 0.182 0.062 0.07  0.117 0.12  0.101 0.091 0.096 0.252]]\n"
          ]
        }
      ],
      "source": [
        "#compute asset returns\n",
        "#array for numerical operations\n",
        "arStockPrices = np.asarray(StockData)\n",
        "[Rows, Cols] = arStockPrices.shape\n",
        "\n",
        "# daily returns for each stock\n",
        "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "meanReturns = np.mean(arReturns, axis=0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
        "print('Variance-Covariance matrix of returns\\n', covReturns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized Portfolio Weights: [     0.      0. 580480.      0.      0. 419520.      0.      0.      0.\n",
            "      0.]\n"
          ]
        }
      ],
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt.exceptions import OptimizationError\n",
        "\n",
        "# Initialize the Efficient Frontier with the previously calculated mean returns and covariance matrix\n",
        "try:\n",
        "    ef = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 1))\n",
        "    # Optimize the portfolio to achieve the maximum Sharpe ratio\n",
        "    raw_weights = ef.max_sharpe(risk_free_rate=0.005)\n",
        "    cleaned_weights = ef.clean_weights()\n",
        "\n",
        "    # Calculate the monetary value of the weights by scaling them up by balance\n",
        "    mvo_weights = np.array([1_000_000 * cleaned_weights[ticker] for ticker in cleaned_weights])\n",
        "    print(\"Optimized Portfolio Weights:\", mvo_weights)\n",
        "\n",
        "except OptimizationError as e:\n",
        "    print(\"Optimization Error:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean Var</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-07-03 09:00:00-04:00</th>\n",
              "      <td>1.001274e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 10:00:00-04:00</th>\n",
              "      <td>1.004380e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 11:00:00-04:00</th>\n",
              "      <td>1.002675e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 12:00:00-04:00</th>\n",
              "      <td>1.000236e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 13:00:00-04:00</th>\n",
              "      <td>1.000783e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 12:00:00-05:00</th>\n",
              "      <td>1.346609e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 13:00:00-05:00</th>\n",
              "      <td>1.348074e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 14:00:00-05:00</th>\n",
              "      <td>1.349317e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 15:00:00-05:00</th>\n",
              "      <td>1.349603e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 16:00:00-05:00</th>\n",
              "      <td>1.344861e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1392 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Mean Var\n",
              "date                                   \n",
              "2023-07-03 09:00:00-04:00  1.001274e+06\n",
              "2023-07-03 10:00:00-04:00  1.004380e+06\n",
              "2023-07-03 11:00:00-04:00  1.002675e+06\n",
              "2023-07-03 12:00:00-04:00  1.000236e+06\n",
              "2023-07-03 13:00:00-04:00  1.000783e+06\n",
              "...                                 ...\n",
              "2024-02-29 12:00:00-05:00  1.346609e+06\n",
              "2024-02-29 13:00:00-05:00  1.348074e+06\n",
              "2024-02-29 14:00:00-05:00  1.349317e+06\n",
              "2024-02-29 15:00:00-05:00  1.349603e+06\n",
              "2024-02-29 16:00:00-05:00  1.344861e+06\n",
              "\n",
              "[1392 rows x 1 columns]"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#last price from the stock data\n",
        "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
        "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
        "\n",
        "# Compute the portfolio value using test data\n",
        "Portfolio_Assets = testData @ Initial_Portfolio\n",
        "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
        "MVO_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result_a2c = (\n",
        "    df_account_value_a2c.set_index(MVO_result.index)\n",
        "    if if_using_a2c\n",
        "    else None\n",
        ")\n",
        "df_result_ddpg = (\n",
        "    df_account_value_ddpg.set_index(MVO_result.index)\n",
        "    if if_using_ddpg\n",
        "    else None\n",
        ")\n",
        "df_result_ppo = (\n",
        "    df_account_value_ppo.set_index(MVO_result.index)\n",
        "    if if_using_ppo\n",
        "    else None\n",
        ")\n",
        "result = pd.DataFrame(\n",
        "    {\n",
        "        \"a2c\": df_result_a2c[\"account_value\"] if if_using_a2c else None,\n",
        "        \"ddpg\": df_result_ddpg[\"account_value\"] if if_using_ddpg else None,\n",
        "        \"ppo\": df_result_ppo[\"account_value\"] if if_using_ppo else None,\n",
        "        \"mvo\": MVO_result[\"Mean Var\"],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a2c</th>\n",
              "      <th>ddpg</th>\n",
              "      <th>ppo</th>\n",
              "      <th>mvo</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-07-03 09:00:00-04:00</th>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.001274e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 10:00:00-04:00</th>\n",
              "      <td>1.000002e+06</td>\n",
              "      <td>9.997399e+05</td>\n",
              "      <td>9.999793e+05</td>\n",
              "      <td>1.004380e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 11:00:00-04:00</th>\n",
              "      <td>9.999204e+05</td>\n",
              "      <td>9.994429e+05</td>\n",
              "      <td>9.999795e+05</td>\n",
              "      <td>1.002675e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 12:00:00-04:00</th>\n",
              "      <td>9.999160e+05</td>\n",
              "      <td>9.997709e+05</td>\n",
              "      <td>9.999701e+05</td>\n",
              "      <td>1.000236e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03 13:00:00-04:00</th>\n",
              "      <td>9.999169e+05</td>\n",
              "      <td>9.997657e+05</td>\n",
              "      <td>9.999648e+05</td>\n",
              "      <td>1.000783e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 12:00:00-05:00</th>\n",
              "      <td>1.258454e+06</td>\n",
              "      <td>1.227701e+06</td>\n",
              "      <td>1.079224e+06</td>\n",
              "      <td>1.346609e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 13:00:00-05:00</th>\n",
              "      <td>1.259610e+06</td>\n",
              "      <td>1.228664e+06</td>\n",
              "      <td>1.077750e+06</td>\n",
              "      <td>1.348074e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 14:00:00-05:00</th>\n",
              "      <td>1.261552e+06</td>\n",
              "      <td>1.229972e+06</td>\n",
              "      <td>1.077674e+06</td>\n",
              "      <td>1.349317e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 15:00:00-05:00</th>\n",
              "      <td>1.261603e+06</td>\n",
              "      <td>1.230042e+06</td>\n",
              "      <td>1.077944e+06</td>\n",
              "      <td>1.349603e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29 16:00:00-05:00</th>\n",
              "      <td>1.257300e+06</td>\n",
              "      <td>1.227072e+06</td>\n",
              "      <td>1.077853e+06</td>\n",
              "      <td>1.344861e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1392 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    a2c          ddpg           ppo  \\\n",
              "date                                                                  \n",
              "2023-07-03 09:00:00-04:00  1.000000e+06  1.000000e+06  1.000000e+06   \n",
              "2023-07-03 10:00:00-04:00  1.000002e+06  9.997399e+05  9.999793e+05   \n",
              "2023-07-03 11:00:00-04:00  9.999204e+05  9.994429e+05  9.999795e+05   \n",
              "2023-07-03 12:00:00-04:00  9.999160e+05  9.997709e+05  9.999701e+05   \n",
              "2023-07-03 13:00:00-04:00  9.999169e+05  9.997657e+05  9.999648e+05   \n",
              "...                                 ...           ...           ...   \n",
              "2024-02-29 12:00:00-05:00  1.258454e+06  1.227701e+06  1.079224e+06   \n",
              "2024-02-29 13:00:00-05:00  1.259610e+06  1.228664e+06  1.077750e+06   \n",
              "2024-02-29 14:00:00-05:00  1.261552e+06  1.229972e+06  1.077674e+06   \n",
              "2024-02-29 15:00:00-05:00  1.261603e+06  1.230042e+06  1.077944e+06   \n",
              "2024-02-29 16:00:00-05:00  1.257300e+06  1.227072e+06  1.077853e+06   \n",
              "\n",
              "                                    mvo  \n",
              "date                                     \n",
              "2023-07-03 09:00:00-04:00  1.001274e+06  \n",
              "2023-07-03 10:00:00-04:00  1.004380e+06  \n",
              "2023-07-03 11:00:00-04:00  1.002675e+06  \n",
              "2023-07-03 12:00:00-04:00  1.000236e+06  \n",
              "2023-07-03 13:00:00-04:00  1.000783e+06  \n",
              "...                                 ...  \n",
              "2024-02-29 12:00:00-05:00  1.346609e+06  \n",
              "2024-02-29 13:00:00-05:00  1.348074e+06  \n",
              "2024-02-29 14:00:00-05:00  1.349317e+06  \n",
              "2024-02-29 15:00:00-05:00  1.349603e+06  \n",
              "2024-02-29 16:00:00-05:00  1.344861e+06  \n",
              "\n",
              "[1392 rows x 4 columns]"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('TkAgg')  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "result.plot()\n",
        "plt.savefig('myplot.png')  # Save the plot as a PNG file\n",
        "plt.close()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
